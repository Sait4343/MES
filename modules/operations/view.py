import streamlit as st
import pandas as pd
from modules.operations.services import OperationsService
from core.config import UserRole

def render():
    st.header("üßµ –î–æ–≤—ñ–¥–Ω–∏–∫ –û–ø–µ—Ä–∞—Ü—ñ–π")
    
    service = OperationsService()
    
    # Create tabs
    tab_list, tab_new, tab_import, tab_export = st.tabs(["üìã –°–ø–∏—Å–æ–∫ —ñ –†–µ–¥–∞–≥—É–≤–∞–Ω–Ω—è", "‚ûï –ù–æ–≤–∞ –æ–ø–µ—Ä–∞—Ü—ñ—è", "üì• –Ü–º–ø–æ—Ä—Ç (Excel)", "üì§ –ï–∫—Å–ø–æ—Ä—Ç"])
    
    # --- TAB 1: LIST & EDIT ---
    # --- TAB 1: LIST & EDIT ---
    with tab_list:
        # 1. Controls Row
        c_search, c_sort, c_limit = st.columns([2, 1, 1])
        
        search_query = c_search.text_input("üîç –ü–æ—à—É–∫", placeholder="–í–≤–µ–¥—ñ—Ç—å –∞—Ä—Ç–∏–∫—É–ª, –∫–ª—é—á –∞–±–æ –Ω–∞–∑–≤—É...", label_visibility="collapsed")
        
        sort_options = {
            "created_at_desc": "üìÖ –°—Ç–≤–æ—Ä–µ–Ω–æ (–Ω–∞–π–Ω–æ–≤—ñ—à—ñ)",
            "created_at_asc": "üìÖ –°—Ç–≤–æ—Ä–µ–Ω–æ (–Ω–∞–π—Å—Ç–∞—Ä—ñ—à—ñ)",
            "updated_at_desc": "üìù –û–Ω–æ–≤–ª–µ–Ω–æ (–Ω–∞–π–Ω–æ–≤—ñ—à—ñ)",
            "article_asc": "üî§ –ê—Ä—Ç–∏–∫—É–ª (–ê-–Ø)",
            "article_desc": "üî§ –ê—Ä—Ç–∏–∫—É–ª (–Ø-–ê)",
            "section_asc": "üè≠ –î—ñ–ª—å–Ω–∏—Ü—è (–ê-–Ø)",
            "norm_desc": "‚è±Ô∏è –ù–æ—Ä–º–∞ —á–∞—Å—É (–Ω–∞–π–±—ñ–ª—å—à–∞)"
        }
        sort_by = c_sort.selectbox("–°–æ—Ä—Ç—É–≤–∞–Ω–Ω—è", options=list(sort_options.keys()), format_func=lambda x: sort_options[x], label_visibility="collapsed")
        
        page_size = c_limit.selectbox("–†—è–¥–∫—ñ–≤ –Ω–∞ —Å—Ç–æ—Ä—ñ–Ω—Ü—ñ", options=[20, 50, 100, 200, 500], index=0, label_visibility="collapsed")

        # 2. Fetch Data
        df = service.get_operations()
        
        if not df.empty:
            # 3. Process Data (Search & Sort) using Pandas
            # Filter
            if search_query:
                query = search_query.lower()
                mask = (
                    df['operation_key'].astype(str).str.lower().str.contains(query) |
                    df['article'].astype(str).str.lower().str.contains(query) |
                    df['operation_number'].astype(str).str.lower().str.contains(query) |
                    df['section'].astype(str).str.lower().str.contains(query)
                )
                df = df[mask]

            # Sort
            if sort_by == 'created_at_desc':
                df = df.sort_values(by='created_at', ascending=False)
            elif sort_by == 'created_at_asc':
                df = df.sort_values(by='created_at', ascending=True)
            elif sort_by == 'updated_at_desc':
                df = df.sort_values(by='updated_at', ascending=False)
            elif sort_by == 'article_asc':
                df = df.sort_values(by='article', ascending=True)
            elif sort_by == 'article_desc':
                df = df.sort_values(by='article', ascending=False)
            elif sort_by == 'section_asc':
                df = df.sort_values(by='section', ascending=True)
            elif sort_by == 'norm_desc':
                df = df.sort_values(by='norm_time', ascending=False)
                
            # 4. Add "No." Column (Sequential 1..N)
            df.insert(0, 'No.', range(1, len(df) + 1))
            
            # 5. Format User Columns
            # Helper to format user
            def format_user(row, prefix):
                email = row.get(f"{prefix}_email")
                name = row.get(f"{prefix}_name")
                if pd.notna(name) and pd.notna(email):
                    return f"{name} ({email})"
                elif pd.notna(email):
                    return email
                return "-"
            
            if 'created_by_email' in df.columns:
                df['created_by_fmt'] = df.apply(lambda x: format_user(x, 'created_by'), axis=1)
            
            if 'updated_by_email' in df.columns:
                df['updated_by_fmt'] = df.apply(lambda x: format_user(x, 'updated_by'), axis=1)
                
            # 6. Pagination
            total_rows = len(df)
            total_pages = (total_rows // page_size) + (1 if total_rows % page_size > 0 else 0)
            
            # Session state for current page
            if "ops_page" not in st.session_state:
                st.session_state.ops_page = 1
                
            # Validate page range (if filter changed)
            if st.session_state.ops_page > total_pages:
                 st.session_state.ops_page = max(1, total_pages)
                 
            current_page = st.session_state.ops_page
            start_idx = (current_page - 1) * page_size
            end_idx = start_idx + page_size
            
            df_page = df.iloc[start_idx:end_idx].copy()
            
            # 7. Display Table
            st.info("üí° –í–∏ –º–æ–∂–µ—Ç–µ —Ä–µ–¥–∞–≥—É–≤–∞—Ç–∏ –¥–∞–Ω—ñ –ø—Ä—è–º–æ –≤ —Ç–∞–±–ª–∏—Ü—ñ. –ù–∞—Ç–∏—Å–Ω—ñ—Ç—å '–ó–±–µ—Ä–µ–≥—Ç–∏ –∑–º—ñ–Ω–∏' —â–æ–± –∑–∞—Ñ—ñ–∫—Å—É–≤–∞—Ç–∏.")
            
            # Determine fixed height: (rows * 35px) + header (~40px)
            # Max height constraint
            calc_height = (len(df_page) * 35) + 40
            
            edited_df = st.data_editor(
                df_page,
                key="ops_editor",
                height=calc_height, 
                column_config={
                    "id": None, # Hide ID
                    "No.": st.column_config.NumberColumn("‚Ññ", width="small", disabled=True),
                    "operation_key": "–ö–ª—é—á",
                    "article": "–ê—Ä—Ç–∏–∫—É–ª",
                    "operation_number": "‚Ññ –û–ø.",
                    "section": "–î—ñ–ª—å–Ω–∏—Ü—è",
                    "norm_time": st.column_config.NumberColumn("–ù–æ—Ä–º–∞ (—Ö–≤)", format="%.2f"),
                    "comment": "–ö–æ–º–µ–Ω—Ç–∞—Ä",
                    "color": "–ö–æ–ª—ñ—Ä",
                    # Metadata (Disabled)
                    "created_at": st.column_config.DatetimeColumn("–°—Ç–≤–æ—Ä–µ–Ω–æ", format="YYYY-MM-DD HH:mm:ss", disabled=True),
                    "updated_at": st.column_config.DatetimeColumn("–û–Ω–æ–≤–ª–µ–Ω–æ", format="YYYY-MM-DD HH:mm:ss", disabled=True),
                    "created_by_fmt": st.column_config.TextColumn("–°—Ç–≤–æ—Ä–∏–≤", disabled=True),
                    "updated_by_fmt": st.column_config.TextColumn("–û–Ω–æ–≤–∏–≤", disabled=True),
                    
                    # Hide raw columns
                    "created_by": None, "updated_by": None,
                    "created_by_email": None, "created_by_name": None,
                    "updated_by_email": None, "updated_by_name": None
                },
                hide_index=True,
                use_container_width=True,
                # Force columns order
                column_order=["No.", "operation_key", "article", "operation_number", "section", "norm_time", "color", "comment", "created_by_fmt", "created_at", "updated_by_fmt", "updated_at"]
            )
            
            # 8. Pagination Controls
            c_prev, c_info, c_next = st.columns([1, 2, 1])
            
            with c_prev:
                if current_page > 1:
                    if st.button("‚¨ÖÔ∏è –ü–æ–ø–µ—Ä–µ–¥–Ω—è"):
                        st.session_state.ops_page -= 1
                        st.rerun()
                        
            with c_info:
                st.markdown(f"<div style='text-align: center'>–°—Ç–æ—Ä—ñ–Ω–∫–∞ <b>{current_page}</b> –∑ <b>{total_pages}</b> (–í—Å—å–æ–≥–æ: {total_rows})</div>", unsafe_allow_html=True)
                
            with c_next:
                if current_page < total_pages:
                    if st.button("–ù–∞—Å—Ç—É–ø–Ω–∞ ‚û°Ô∏è"):
                        st.session_state.ops_page += 1
                        st.rerun()

            # 9. Save Changes Logic
            # Compare edited_df with df_page (using IDs)
            # Simplified: Button to save all
            
            if st.button("üíæ –ó–±–µ—Ä–µ–≥—Ç–∏ –∑–º—ñ–Ω–∏ –≤ —Ç–∞–±–ª–∏—Ü—ñ", type="primary"):
                with st.spinner("–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è..."):
                    updated_count = 0
                    current_user_id = st.session_state.user.id if st.session_state.get("user") else None
                    
                    for index, row in edited_df.iterrows():
                        op_id = row.get("id")
                        
                        # Prepare data
                        row_data = {
                            "operation_key": row["operation_key"],
                            "article": row["article"],
                            "operation_number": row["operation_number"],
                            "section": row["section"],
                            "norm_time": row["norm_time"],
                            "comment": row["comment"],
                            "color": row["color"]
                        }
                        
                        if pd.isna(op_id):
                            continue # Ignore new rows here? or Create? 
                            # Data_editor dynamic rows usually have None ID.
                            # But wait, original DF has IDs.
                            # If row was added via "dynamic" num_rows, it has no ID.
                            # service.create_operation(row_data, user_id=current_user_id)
                        else:
                            # It's an update
                            # Check change? For now, we update if ID exists.
                            # Optimization: only update if changed.
                            service.update_operation(op_id, row_data, user_id=current_user_id)
                            updated_count += 1
                            
                    st.success(f"–û–Ω–æ–≤–ª–µ–Ω–æ {updated_count} –∑–∞–ø–∏—Å—ñ–≤!")
                    st.rerun()

        else:
            st.info("–î–æ–≤—ñ–¥–Ω–∏–∫ –ø–æ—Ä–æ–∂–Ω—ñ–π. –î–æ–¥–∞–π—Ç–µ –æ–ø–µ—Ä–∞—Ü—ñ—ó —á–µ—Ä–µ–∑ —ñ–º–ø–æ—Ä—Ç –∞–±–æ –≤–∫–ª–∞–¥–∫—É '–ù–æ–≤–∞ –æ–ø–µ—Ä–∞—Ü—ñ—è'.")

    # --- TAB 2: NEW OPERATION ---
    with tab_new:
        st.subheader("‚ûï –î–æ–¥–∞—Ç–∏ –Ω–æ–≤—É –æ–ø–µ—Ä–∞—Ü—ñ—é")
        with st.form("new_op_form"):
            c1, c2 = st.columns(2)
            op_key = c1.text_input("–ö–ª—é—á –æ–ø–µ—Ä–∞—Ü—ñ—ó (Operation Key)", help="–£–Ω—ñ–∫–∞–ª—å–Ω–∏–π —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ç–æ—Ä")
            article = c2.text_input("–ê—Ä—Ç–∏–∫—É–ª")
            
            c3, c4 = st.columns(2)
            op_num = c3.text_input("–ù–æ–º–µ—Ä –æ–ø–µ—Ä–∞—Ü—ñ—ó")
            section = c4.text_input("–î—ñ–ª—å–Ω–∏—Ü—è (Section)")
            
            c5, c6 = st.columns(2)
            norm_time = c5.number_input("–ù–æ—Ä–º–∞ —á–∞—Å—É (—Ö–≤)", min_value=0.0, step=0.01)
            color = c6.color_picker("–ö–æ–ª—ñ—Ä", "#E0E0E0")
            
            comment = st.text_area("–ö–æ–º–µ–Ω—Ç–∞—Ä")
            
            if st.form_submit_button("–°—Ç–≤–æ—Ä–∏—Ç–∏ –æ–ø–µ—Ä–∞—Ü—ñ—é"):
                if not op_key or not article:
                    st.error("–ö–ª—é—á —Ç–∞ –ê—Ä—Ç–∏–∫—É–ª —î –æ–±–æ–≤'—è–∑–∫–æ–≤–∏–º–∏!")
                else:
                    data = {
                        "operation_key": op_key,
                        "article": article,
                        "operation_number": op_num,
                        "section": section,
                        "norm_time": norm_time,
                        "comment": comment,
                        "color": color
                    }
                    current_user_id = st.session_state.user.id if st.session_state.get("user") else None
                    success, msg = service.create_operation(data, user_id=current_user_id)
                    if success:
                        st.success("–û–ø–µ—Ä–∞—Ü—ñ—é –¥–æ–¥–∞–Ω–æ!")
                        st.rerun()
                    else:
                        st.error(f"–ü–æ–º–∏–ª–∫–∞: {msg}")

    # --- TAB 3: IMPORT ---
    with tab_import:
        if st.session_state.role not in [UserRole.ADMIN, UserRole.MANAGER]:
            st.warning("‚ö†Ô∏è –Ü–º–ø–æ—Ä—Ç –¥–æ—Å—Ç—É–ø–Ω–∏–π —Ç—ñ–ª—å–∫–∏ –¥–ª—è –ê–¥–º—ñ–Ω—ñ—Å—Ç—Ä–∞—Ç–æ—Ä—ñ–≤ —Ç–∞ –ú–µ–Ω–µ–¥–∂–µ—Ä—ñ–≤.")
        else:
            st.markdown("### –Ü–º–ø–æ—Ä—Ç –æ–ø–µ—Ä–∞—Ü—ñ–π –∑ Excel")
            uploaded_file = st.file_uploader("–ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ —Ñ–∞–π–ª", type=["xlsx", "xls"])
            
            if uploaded_file:
                try:
                    # 1. Inspect Excel File for Sheets
                    xls = pd.ExcelFile(uploaded_file)
                    sheet_names = xls.sheet_names
                    
                    st.write(f"–ó–Ω–∞–π–¥–µ–Ω–æ –∞—Ä–∫—É—à—ñ–≤: {len(sheet_names)}")
                    selected_sheet = st.selectbox("–û–±–µ—Ä—ñ—Ç—å –∞—Ä–∫—É—à –¥–ª—è —ñ–º–ø–æ—Ä—Ç—É", sheet_names)
                    
                    # 2. Read Data from Selected Sheet
                    df_raw = pd.read_excel(uploaded_file, sheet_name=selected_sheet)
                    
                    st.success(f"–§–∞–π–ª –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ! –†—è–¥–∫—ñ–≤: {len(df_raw)}")
                    st.write("–ü–æ–ø–µ—Ä–µ–¥–Ω—ñ–π –ø–µ—Ä–µ–≥–ª—è–¥ (–ø–µ—Ä—à—ñ 3 —Ä—è–¥–∫–∏):")
                    # Convert to string for display to avoid Arrow serialization errors with mixed types (e.g. int/str in same col)
                    st.dataframe(df_raw.head(3).astype(str))
                    
                    st.divider()
                    st.subheader("üîó –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Å—Ç–æ–≤–ø—Ü—ñ–≤")
                    st.info("–û–±–µ—Ä—ñ—Ç—å, —è–∫–∏–π —Å—Ç–æ–≤–ø–µ—Ü—å –∑ –≤–∞—à–æ–≥–æ —Ñ–∞–π–ª—É –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î –ø–æ–ª—é –≤ –±–∞–∑—ñ –¥–∞–Ω–∏—Ö.")
                    
                    excel_headers = ["(–ü—Ä–æ–ø—É—Å—Ç–∏—Ç–∏)"] + list(df_raw.columns)
                    
                    # DB Fields we need to map
                    db_fields = {
                        "operation_key": "–ö–ª—é—á –æ–ø–µ—Ä–∞—Ü—ñ—ó",
                        "article": "–ê—Ä—Ç–∏–∫—É–ª",
                        "operation_number": "‚Ññ –æ–ø–µ—Ä–∞—Ü—ñ—ó",
                        "section": "–î—ñ–ª—å–Ω–∏—Ü—è",
                        "norm_time": "–ù–æ—Ä–º–∞ —á–∞—Å—É (—Ö–≤)",
                        "comment": "–ö–æ–º–µ–Ω—Ç–∞—Ä",
                        "color": "–ö–æ–ª—ñ—Ä" # Optional but good to have
                    }
                    
                    mapping = {}
                    cols = st.columns(3)
                    
                    for i, (db_field, label) in enumerate(db_fields.items()):
                        # Try to auto-guess index
                        default_idx = 0
                        for idx, h in enumerate(excel_headers):
                            if h != "(–ü—Ä–æ–ø—É—Å—Ç–∏—Ç–∏)" and any(x in h.lower() for x in label.lower().split()):
                                default_idx = idx
                                break
                        
                        with cols[i % 3]:
                            selected_col = st.selectbox(
                                f"–ü–æ–ª–µ –ë–î: **{label}**", 
                                options=excel_headers, 
                                index=default_idx,
                                key=f"map_{db_field}"
                            )
                            if selected_col != "(–ü—Ä–æ–ø—É—Å—Ç–∏—Ç–∏)":
                                mapping[db_field] = selected_col
                    
                    st.divider()
                    
                    st.divider()
                    
                    if not mapping:
                        st.warning("‚ö†Ô∏è –°–ø–æ—á–∞—Ç–∫—É —Å–ø—ñ–≤—Å—Ç–∞–≤—Ç–µ —Ö–æ—á–∞ –± –æ–¥–∏–Ω —Å—Ç–æ–≤–ø–µ—Ü—å.")
                    else:
                        # --- PRE-IMPORT VALIDATION ---
                        # 1. Identify mapped columns in the dataframe
                        mapped_excel_cols = [v for k, v in mapping.items() if v]
                        
                        # 2. Analyze rows
                        # We consider a row "empty" if ALL mapped columns are empty/NaN
                        # We consider a row "valid" if at least one mapped column has data
                        
                        # Create a subset for analysis
                        df_mapped_subset = df_raw[mapped_excel_cols]
                        
                        # Count total
                        total_rows = len(df_mapped_subset)
                        
                        # Identify empty rows (all null/nan in mapped cols)
                        # We use .isna().all(axis=1) (or check for empty strings too if needed)
                        # Let's treat empty strings as NaN for this check
                        is_empty_mask = df_mapped_subset.replace(r'^\s*$', pd.NA, regex=True).isna().all(axis=1)
                        empty_rows_count = is_empty_mask.sum()
                        valid_rows_count = total_rows - empty_rows_count
                        
                        # Display Stats
                        st.markdown("#### üìä –ê–Ω–∞–ª—ñ–∑ –¥–∞–Ω–∏—Ö")
                        c_stat1, c_stat2, c_stat3 = st.columns(3)
                        c_stat1.metric("–í—Å—å–æ–≥–æ —Ä—è–¥–∫—ñ–≤", total_rows)
                        c_stat2.metric("–ü—É—Å—Ç—ñ —Ä—è–¥–∫–∏", empty_rows_count, delta_color="inverse")
                        c_stat3.metric("–î–æ —ñ–º–ø–æ—Ä—Ç—É", valid_rows_count)
                        
                        # Options
                        skip_empty = st.checkbox("üö´ –ù–µ —ñ–º–ø–æ—Ä—Ç—É–≤–∞—Ç–∏ –ø—É—Å—Ç—ñ —Ä—è–¥–∫–∏", value=True)
                        
                        if valid_rows_count == 0:
                            st.error("‚ùå –ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –¥–ª—è —ñ–º–ø–æ—Ä—Ç—É (–≤—Å—ñ —Ä—è–¥–∫–∏ –ø—É—Å—Ç—ñ –∞–±–æ –Ω–µ –≤–∏–±—Ä–∞–Ω—ñ —Å—Ç–æ–≤–ø—Ü—ñ).")
                        else:
                            if st.button("üöÄ –í–∏–∫–æ–Ω–∞—Ç–∏ —ñ–º–ø–æ—Ä—Ç"):
                                with st.spinner("–Ü–º–ø–æ—Ä—Ç—É—î–º–æ –¥–∞–Ω—ñ..."):
                                    # Filter DF if needed
                                    if skip_empty:
                                        # Keep only rows that are NOT empty
                                        df_to_import = df_raw[~is_empty_mask]
                                    else:
                                        df_to_import = df_raw
                                        
                                    current_user_id = st.session_state.user.id if st.session_state.get("user") else None
                                    s_count, e_count = service.import_operations(df_to_import, mapping, user_id=current_user_id)
                                
                                if e_count == 0:
                                    st.success(f"‚úÖ –£—Å–ø—ñ—à–Ω–æ —ñ–º–ø–æ—Ä—Ç–æ–≤–∞–Ω–æ {s_count} —Ä—è–¥–∫—ñ–≤!")
                                    st.balloons()
                                else:
                                    st.warning(f"–Ü–º–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –£—Å–ø—ñ—à–Ω–æ: {s_count}, –ü–æ–º–∏–ª–æ–∫: {e_count}")
                                    
                except Exception as e:
                    st.error(f"–ü–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è –∞–±–æ –æ–±—Ä–æ–±–∫–∏ —Ñ–∞–π–ª—É: {e}")

    # --- TAB 3: EXPORT ---
    with tab_export:
        st.markdown("### –ï–∫—Å–ø–æ—Ä—Ç –æ–ø–µ—Ä–∞—Ü—ñ–π –≤ Excel")
        
        # Re-fetch or reuse if appropriate, but cleaner to fetch fresh
        df_export = service.get_operations()
        
        if df_export.empty:
            st.info("–ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –¥–ª—è –µ–∫—Å–ø–æ—Ä—Ç—É.")
        else:
            st.write(f"–£ –±–∞–∑—ñ –∑–Ω–∞–π–¥–µ–Ω–æ {len(df_export)} –∑–∞–ø–∏—Å—ñ–≤.")
            
            # Convert to Excel in memory
            import io
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                df_export.to_excel(writer, index=False, sheet_name='Operations')
            
            excel_data = output.getvalue()
            
            st.download_button(
                label="üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ Excel",
                data=excel_data,
                file_name="operations_catalog.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
